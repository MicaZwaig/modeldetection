<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Detector de Deepfake — Pro (Local)</title>
  <style>
    :root{
      --bg: #0b1020;
      --card: rgba(255,255,255,0.06);
      --card-strong: rgba(255,255,255,0.12);
      --text: #eaf2ff;
      --muted: #9fb0cc;
      --accent: #7aa2ff;
      --accent-2:#8af0d6;
      --danger:#ff6b6b;
      --success:#00d39b;
      --warning:#ffb86b;
      --shadow: 0 15px 40px rgba(0,0,0,0.35);
      --radius: 16px;
    }
    *{box-sizing:border-box}
    body{
      margin:0; font-family: Inter, ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial;
      color:var(--text);
      background: radial-gradient(1200px 600px at 15% 0%, #151a33 0%, #0b1020 40%, #0b1020 100%);
      min-height:100svh;
    }
    header{ display:flex; align-items:center; justify-content:space-between; gap:12px; padding:24px clamp(16px, 4vw, 40px); }
    .brand{ display:flex; align-items:center; gap:12px; font-weight:700; letter-spacing:.3px; }
    .pill{ padding:.35rem .7rem; border-radius:999px; background:linear-gradient(90deg,var(--accent),var(--accent-2)); color:#0b1020; font-size:.8rem; font-weight:700; }
    .status{ display:flex; gap:8px; align-items:center; flex-wrap:wrap; }
    .badge{ padding:.25rem .55rem; border-radius:999px; border:1px solid var(--card-strong); background:rgba(255,255,255,.06); font-size:.8rem; }
    .container{ max-width:1100px; margin:0 auto; padding:0 clamp(16px, 4vw, 40px) 40px; }
    .grid{ display:grid; grid-template-columns: 1.2fr .8fr; gap:24px; } @media (max-width: 980px){ .grid{ grid-template-columns:1fr; } }
    .card{ background:var(--card); border:1px solid var(--card-strong); border-radius:var(--radius); box-shadow:var(--shadow); backdrop-filter:saturate(120%) blur(6px); }
    .panel{ padding:20px; }
    .title{ font-size:1.25rem; font-weight:700; margin:0 0 6px; }
    .subtitle{ color:var(--muted); margin:0 0 14px; }
    .dropzone{ border:2px dashed rgba(255,255,255,.18); border-radius:14px; padding:22px; display:flex; align-items:center; gap:14px; background:linear-gradient(180deg, rgba(255,255,255,.05), rgba(255,255,255,.02)); transition: .25s ease; }
    .dropzone.drag{ border-color: var(--accent); background: linear-gradient(180deg, rgba(122,162,255,.15), rgba(138,240,214,.08)); }
    .dropzone input{ display:none; }
    .dropzone .dz-label{ flex:1; }
    .dropzone button{ background:var(--accent); color:#0b1020; border:none; border-radius:12px; padding:.75rem 1rem; font-weight:700; cursor:pointer; }
    .actions{ display:flex; gap:10px; flex-wrap:wrap; margin-top:14px; }
    .btn{ padding:.75rem 1rem; border-radius:12px; border:1px solid var(--card-strong); background:rgba(255,255,255,.06); color:var(--text); font-weight:700; cursor:pointer; transition:.2s ease; }
    .btn:hover{ transform: translateY(-1px); background:rgba(255,255,255,.1); }
    .btn.primary{ background:linear-gradient(90deg, var(--accent), var(--accent-2)); color:#0b1020; border:none; }
    .btn.ghost{ background:transparent; }
    .video-wrap{ position:relative; overflow:hidden; border-radius:12px; background:#000; aspect-ratio:16/9; display:grid; place-items:center; }
    video{ width:100%; height:100%; object-fit:contain; background:#000; }
    .progress{ height:10px; width:100%; background:rgba(255,255,255,.08); border-radius:999px; overflow:hidden; }
    .progress .bar{ height:100%; width:0%; background:linear-gradient(90deg, var(--accent), var(--accent-2)); transition: width .2s ease; }
    .result-card{ display:grid; grid-template-columns: 160px 1fr; gap:18px; align-items:center; } @media (max-width: 520px){ .result-card{ grid-template-columns:1fr; } }
    .gauge{ width:160px; height:160px; position:relative; }
    .gauge canvas{ position:absolute; inset:0; }
    .gauge .center{ position:absolute; inset:0; display:grid; place-items:center; text-align:center; }
    .gauge .center .big{ font-size:1.75rem; font-weight:800; }
    .gauge .center .small{ color:var(--muted); font-size:.9rem; }
    .legend{ display:grid; gap:10px; }
    .metric-row{ display:grid; grid-template-columns: 160px 1fr auto; gap:10px; align-items:center; position:relative; }
    .metric-row .name{ color:var(--muted); font-size:.9rem; cursor:help; }
    .metric-row .bar{ height:10px; background:rgba(255,255,255,.08); border-radius:999px; overflow:hidden; }
    .metric-row .bar > span{ display:block; height:100%; width:0%; background:linear-gradient(90deg, var(--warning), var(--danger)); }
    .metric-row .val{ font-weight:700; }
    .tip{ font-size:.9rem; color:var(--muted); }
    .dot{ width:8px; height:8px; display:inline-block; border-radius:999px; margin-right:6px; }
    footer{ color:#92a3c3; opacity:.9; font-size:.9rem; text-align:center; padding:18px; }
    .kbd{background:rgba(255,255,255,.12); padding:.2rem .45rem; border-radius:6px; border:1px solid rgba(255,255,255,.2);} .danger{ color: var(--danger); } .success{ color: var(--success); }
    .row{ display:flex; gap:10px; align-items:center; flex-wrap:wrap; }
    .mini{ font-size:.8rem; color:var(--muted); }
    .slider{ width:220px; }

    /* Tooltip flotante global */
    #metricTooltip{
      position:fixed; top:0; left:0; z-index:9999;
      background:rgba(13,18,38,.98);
      color:var(--text);
      border:1px solid var(--card-strong);
      box-shadow:var(--shadow);
      border-radius:10px; padding:.6rem .75rem;
      font-size:.85rem; max-width:320px;
      opacity:0; transform: translateY(-4px) scale(.98);
      pointer-events:none; transition:.12s ease;
      white-space:normal; overflow-wrap:anywhere;
    }
    #metricTooltip.show{ opacity:1; transform: translateY(0) scale(1); }
  </style>
  <!-- ORT Web (ONNXRuntime) -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <!-- MediaPipe Tasks Vision (FaceLandmarker) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/wasm/vision_bundle.js"></script>
</head>
<body>
  <header>
    <div class="brand">
      <span class="pill">Pro</span>
      <div>Detector de Deepfake (todo local)</div>
    </div>
    <div class="status">
      <span class="badge" id="status-onnx">Modelo IA: cargando…</span>
      <span class="badge" id="status-face">Landmarks: cargando…</span>
      <span class="badge" id="status-mode">Modo: heurístico+IA</span>
    </div>
  </header>

  <main class="container grid">
    <!-- LEFT: input + preview -->
    <section class="card panel">
      <h2 class="title">1) Cargá un video</h2>
      <p class="subtitle">Se muestrean hasta 5 fps y se analiza el rostro con landmarks + un modelo ONNX (si está disponible) y métricas avanzadas.</p>

      <label class="dropzone" id="dropzone">
        <input id="file" type="file" accept="video/*" />
        <div class="dz-label">
          <strong>Arrastrá y soltá</strong> un video acá, o <span class="kbd">clic</span> para elegir.
          <div class="tip" style="margin-top:6px">Consejo: usar 10–60s con rostro visible. También se analiza el <strong>nombre del archivo</strong>.</div>
        </div>
        <button type="button" id="pickBtn">Elegir archivo</button>
      </label>

      <div class="actions">
        <button class="btn primary" id="analyzeBtn" disabled>Analizar video</button>
        <button class="btn" id="exportBtn" disabled>Exportar reporte (.json)</button>
        <button class="btn ghost" id="resetBtn">Reiniciar</button>

        <div class="row mini">
          Umbral de sospecha:
          <input id="thres" class="slider" type="range" min="30" max="80" value="60"/>
          <span id="thresVal">60%</span>
        </div>

        <div class="row mini">
          Perfil:
          <select id="profile">
            <option value="balanced">Equilibrado</option>
            <option value="aggressive" selected>Agresivo (IA realista)</option>
          </select>
        </div>
      </div>

      <div style="margin-top:16px" class="video-wrap">
        <video id="video" controls crossorigin="anonymous"></video>
      </div>

      <div style="margin-top:16px" class="progress" aria-label="Progreso de análisis">
        <div class="bar" id="progressBar"></div>
      </div>

      <div style="margin-top:10px" class="tip">
        Este modo usa: <em>modelo IA ONNX (si carga)</em> + <em>parpadeo</em>, <em>sincronía labios–audio</em>, <em>DCT alta frecuencia</em>, <em>consistencia de piel</em>, <em>compresión</em>, <em>nitidez</em>, <em>saturación</em> y <em>pistas del nombre</em>.
      </div>
    </section>

    <!-- RIGHT: results -->
    <aside class="card panel">
      <h2 class="title">2) Resultado</h2>
      <p class="subtitle">Probabilidad estimada de deepfake. Si el modelo IA no está disponible, se usa el modo heurístico reforzado.</p>

      <div class="result-card">
        <div class="gauge">
          <canvas id="gauge" width="160" height="160" aria-label="Porcentaje de sospecha"></canvas>
          <div class="center">
            <div class="big" id="pct">—%</div>
            <div class="small" id="label">Sin análisis</div>
          </div>
        </div>
        <div class="legend" id="legend"></div>
      </div>

      <div style="margin-top:14px" class="tip">
        <strong>Interpretación:</strong>
        <ul style="margin:.4rem 0 .2rem 1.1rem; padding:0">
          <li><span class="success">0–35%</span> auténtico probable</li>
          <li><span class="warning" style="color:var(--warning)">35–65%</span> incierto</li>
          <li><span class="danger">65–100%</span> potencial deepfake</li>
        </ul>
      </div>
    </aside>
  </main>

  <!-- Work canvases -->
  <canvas id="work" width="320" height="180" style="display:none"></canvas>
  <canvas id="face" width="224" height="224" style="display:none"></canvas>
  <canvas id="blur" width="160" height="90" style="display:none"></canvas>

  <!-- Tooltip global -->
  <div id="metricTooltip" role="tooltip" aria-hidden="true"></div>

  <script>
  // ================== Config ==================
  const CFG = {
    modelUrl: 'models/df_detector_xceptionlite.onnx', // Cambiá por tu ONNX. Si no existe, el análisis sigue sin IA.
    faceLandmarkerAsset: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
    fps: 5,
    maxFrames: 450,
    capDuration: 120, // segundos
    faceCropScale: 1.3 // escala extra sobre el rostro para incluir contorno
  };

  // ================== UI refs ==================
  const $ = sel => document.querySelector(sel);
  const fileInput = $('#file');
  const dropzone = $('#dropzone');
  const pickBtn = $('#pickBtn');
  const analyzeBtn = $('#analyzeBtn');
  const exportBtn = $('#exportBtn');
  const resetBtn = $('#resetBtn');
  const video = $('#video');
  const bar = $('#progressBar');
  const gaugeCanvas = $('#gauge');
  const pctEl = $('#pct');
  const labelEl = $('#label');
  const legendEl = $('#legend');
  const thres = $('#thres');
  const thresVal = $('#thresVal');
  const stOnnx = $('#status-onnx');
  const stFace = $('#status-face');
  const profileSel = $('#profile');
  const tooltip = $('#metricTooltip');

  let currentFile = null;
  let lastReport = null;
  let audioBuffer = null;

  thres.addEventListener('input', ()=> thresVal.textContent = thres.value + '%');

  pickBtn.addEventListener('click', () => fileInput.click());
  dropzone.addEventListener('dragover', (e)=>{ e.preventDefault(); dropzone.classList.add('drag'); });
  dropzone.addEventListener('dragleave', ()=> dropzone.classList.remove('drag'));
  dropzone.addEventListener('drop', (e)=>{ e.preventDefault(); dropzone.classList.remove('drag'); const f=e.dataTransfer.files?.[0]; if(f) loadFile(f); });
  fileInput.addEventListener('change', (e)=>{ const f=e.target.files?.[0]; if(f) loadFile(f); });
  resetBtn.addEventListener('click', resetAll);

  function resetAll(){
    video.removeAttribute('src'); video.load(); analyzeBtn.disabled = true; exportBtn.disabled = true; bar.style.width='0%';
    setGauge(0, 'Sin análisis'); legendEl.innerHTML=''; lastReport=null; currentFile=null; audioBuffer=null;
  }

  function loadFile(file){
    currentFile = file; const url = URL.createObjectURL(file);
    video.src = url; video.currentTime = 0; bar.style.width = '0%'; analyzeBtn.disabled = false; exportBtn.disabled = true; setGauge(0, 'Listo para analizar');
    // Pre-decode audio for lipsync metric
    const reader = new FileReader(); reader.onload = async () => { try{ const ac = new (window.AudioContext||window.webkitAudioContext)(); audioBuffer = await ac.decodeAudioData(reader.result); }catch{} }; reader.readAsArrayBuffer(file);
  }

  exportBtn.addEventListener('click', ()=>{ if(!lastReport) return; const blob = new Blob([JSON.stringify(lastReport,null,2)], {type:'application/json'}); const a=document.createElement('a'); a.href=URL.createObjectURL(blob); a.download=`deepfake-reporte-${Date.now()}.json`; a.click(); });

  // ================== IA & Landmarks init ==================
  let session = null; let modelReady=false; let faceReady=false; let FaceLandmarkerRef=null; let FilesetResolverRef=null; let faceLandmarker=null;
  (async function init(){
    try{
      // ONNX Runtime
      session = await ort.InferenceSession.create(CFG.modelUrl, { executionProviders: ['wasm'] });
      modelReady = true; stOnnx.textContent = 'Modelo IA: cargado'; stOnnx.style.borderColor = '#00d39b';
    }
    catch(e){ stOnnx.textContent = ''; stOnnx.style.borderColor = '#ffb86b'; }

    try{
      FilesetResolverRef = window.FilesetResolver; FaceLandmarkerRef = window.FaceLandmarker;
      const fileset = await FilesetResolverRef.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/wasm');
      faceLandmarker = await FaceLandmarkerRef.createFromOptions(fileset, {
        baseOptions: { modelAssetPath: CFG.faceLandmarkerAsset },
        outputFaceBlendshapes: true,
        runningMode: 'IMAGE',
        numFaces: 1
      });
      faceReady = true; stFace.textContent = 'Landmarks: ok'; stFace.style.borderColor = '#00d39b';
    }catch(e){ stFace.textContent = ''; stFace.style.borderColor = '#ff6b6b'; }
  })();

  // ================== Analysis ==================
  const work = $('#work'); const wctx = work.getContext('2d', { willReadFrequently:true });
  const faceC = $('#face'); const fctx = faceC.getContext('2d', { willReadFrequently:true });
  const blurC = $('#blur'); const bctx = blurC.getContext('2d', { willReadFrequently:true });

  const once = (el, ev) => new Promise(r => el.addEventListener(ev, function h(e){ el.removeEventListener(ev, h); r(e); }, {once:true}));

  analyzeBtn.addEventListener('click', async ()=>{
    analyzeBtn.disabled = true; exportBtn.disabled = true; legendEl.innerHTML='';
    try{
      const report = await analyzeVideo(video, (p)=> bar.style.width = p + '%');
      lastReport = report; exportBtn.disabled = false; renderReport(report);
    }catch(err){ console.error(err); alert('Error procesando el video: '+ err.message); }
    finally{ analyzeBtn.disabled = false; }
  });

  async function analyzeVideo(video, onProgress){
    await ensureMetadata(video);
    const fps = CFG.fps; const maxFrames=CFG.maxFrames; const duration = Math.min(video.duration||0, CFG.capDuration);
    const {frames, times} = await captureFrames(video, fps, maxFrames, duration, onProgress);
    if(frames.length < 6) throw new Error('Muy pocos cuadros para analizar');

    // Series
    const per = [];
    const earSeries = [];
    const marSeries = [];
    const noiseSeries = [];
    const faceContrastSeries = [];
    const satMeanSeries = [];
    const satP95Series  = [];

    for (let i=0;i<frames.length;i++){
      const img = frames[i];
      const base = frameStats(img);

      // Saturación global
      const sat = saturationStats(img);
      satMeanSeries.push(sat.meanS);
      satP95Series.push(sat.p95S);

      // Landmarks/cara
      let ear=null, mar=null, facePatch=null;
      if (faceReady) {
        const faceInfo = detectFace(img);
        if (faceInfo){ ear=faceInfo.ear; mar=faceInfo.mar; facePatch=faceInfo.patch; }
      }

      // ONNX
      let onnxProb = null;
      if (modelReady && facePatch){ onnxProb = await runOnnx(facePatch); }

      // DCT y piel
      const dctHFv = facePatch ? dctHighFreq(facePatch) : dctHighFreq(img);
      const skinVar = facePatch ? skinChromVar(facePatch) : 0;

      // Ruido HF global
      const nRms = frameNoiseRMS(img);
      noiseSeries.push(nRms);

      // Contraste local en cara
      if (facePatch) faceContrastSeries.push(localContrast(facePatch));

      per.push({ ...base, onnxProb, dctHF: dctHFv, skinVar });
      if (ear!==null) earSeries.push(ear);
      if (mar!==null) marSeries.push(mar);
      if(onProgress) onProgress(Math.round(((i+1)/frames.length)*100));
    }

    // Vectores
    const meanY = per.map(p=>p.meanY);
    const block = per.map(p=>p.blockiness);
    const sharp = per.map(p=>p.lapEnergy);
    const dctHF = per.map(p=>p.dctHF);

    // Variabilidad temporal (“perfección”)
    const vBright = stdDev(diff(meanY));
    const vBlock  = stdDev(block);
    const vSharp  = stdDev(sharp);
    const vSat    = stdDev(satMeanSeries);
    const meanNoise = mean(noiseSeries);
    const vNoise  = stdDev(noiseSeries);
    const faceContrMean = faceContrastSeries.length ? mean(faceContrastSeries) : null;

    // Contraste global (muestrar 3 frames)
    const sampleIdx = [0, Math.floor(frames.length/2), frames.length-1].filter(i=>i>=0);
    let globalContrastSd = 0, globalRange = 0;
    if(sampleIdx.length){
      const vals = sampleIdx.map(i => contrastGlobal(frames[i]));
      globalContrastSd = mean(vals.map(v=>v.sd));
      globalRange = mean(vals.map(v=>v.range));
    }

    // Bitrate aproximado (info)
    const bitrate = approxBitratebps(currentFile, duration);

    // ====== Riesgos (sin movimiento) ======
    const prof = (profileSel?.value || 'aggressive');

    // Flicker: U‑shape (muy bajo o muy alto = riesgo). Perfil agresivo es más sensible a “demasiado bajo”.
    const flickerRisk = uShape(vBright, 0.6, 3.4);
    const flickerRiskAgg = uShape(vBright, 0.4, 2.6);

    // Compresión: promedio alto O uniformidad temporal excesiva
    const blockMeanRisk = uShape(mean(block), 0.6, 2.0);
    const blockUniformRisk = scale(1 - vBlock, 0.0, 0.6);
    const blockinessRisk = Math.max(blockMeanRisk, blockUniformRisk);

    // Nitidez: exceso y uniformidad
    const sharpMeanRisk = uShape(mean(sharp), 12, 36);
    const sharpUniformRisk = scale(1 - vSharp, 0.0, 1.6);
    const sharpnessRisk = Math.max(sharpMeanRisk, sharpUniformRisk);

    // DCT alta frecuencia (caras muy “crosp”/detalladas)
    const dctRisk = clamp(mean(dctHF), 0, 1);

    // Saturación: nivel/pico altos y MUY estable
    const satLevelRisk = scale(mean(satMeanSeries), 0.35, 0.7);
    const satPeakRisk  = scale(mean(satP95Series), 0.6, 0.95);
    const satStabilityRisk = scale(1 - vSat, 0.0, 0.12);
    const saturationRisk = Math.max(satLevelRisk, satPeakRisk, satStabilityRisk);

    // Contraste global tipo “demo”
    const globalContrastRisk = scale(globalRange, 60, 150);

    // Ruido de sensor irreal (bajo y estable)
    const noiseLevelRisk = lowRisk(meanNoise, 2.0, 6.0);
    const noiseStabilityRisk = scale(1 - vNoise, 0.0, 1.2);
    const sensorNoiseRisk = Math.max(noiseLevelRisk, noiseStabilityRisk);

    // Piel plana (cara muy tersa/estable)
    let skinFlatRisk = 0.3;
    if (faceContrMean !== null) {
      const lowContrast = lowRisk(faceContrMean, 6.0, 18.0);
      const lowChromaVar = lowRisk( mean(per.map(p=>p.skinVar)), 0.12, 0.28 );
      skinFlatRisk = Math.max(lowContrast, lowChromaVar);
    }

    // Lipsync / Blink
    const lipsync = await lipsyncCorrelation(times, marSeries, audioBuffer);
    const lipsyncRisk = lipsync?.risk01 ?? 0.3;
    const blink = blinkStats(earSeries, fps);
    const blinkRisk = blink ? blink.risk01 : 0.3;

    // Nombre de archivo
    const nameRisk = filenameRisk(currentFile?.name || '');

    // ONNX (si está)
    const onnxProb = mean(per.filter(p=>p.onnxProb!=null).map(p=>p.onnxProb)) || null;

    // ====== Métricas y pesos ======
    const metrics = [
      {key:'onnx',   name:'Modelo IA (ONNX)',            val: onnxProb==null?0:onnxProb, desc:'Salida del clasificador ONNX sobre rostro 224×224 (0 real – 1 fake).'},
      {key:'flicker',name:'Flicker de brillo',           val: (prof==='aggressive'? flickerRiskAgg : flickerRisk), desc:'U‑shape: variación de luminancia muy baja o muy alta es sospechosa.'},
      {key:'dct',    name:'Alta frecuencia DCT',         val: dctRisk, desc:'Energía relativa en altas frecuencias (texturas/bordes artificiales).'},
      {key:'block',  name:'Compresión uniforme',         val: blockinessRisk, desc:'Promedio alto o compresión excesivamente uniforme en el tiempo.'},
      {key:'sharp',  name:'Nitidez “perfecta”',          val: sharpnessRisk, desc:'Exceso/falta de nitidez o nitidez demasiado estable.'},
      {key:'sat',    name:'Saturación elevada/estable',  val: saturationRisk, desc:'Saturación alta (mean/p95) y muy estable sugiere look sintético.'},
      {key:'gcontrast', name:'Contraste global alto',    val: globalContrastRisk, desc:'Rango tonal muy amplio típico de “demo reel” o post digital.'},
      {key:'sensor', name:'Ruido de sensor irreal',      val: sensorNoiseRisk, desc:'Ruido muy bajo y constante (sin “grano” natural) es sospechoso.'},
      {key:'skin',   name:'Piel plana/estable',          val: skinFlatRisk, desc:'Bajo contraste y crominancia demasiado estable en la cara.'},
      {key:'lips',   name:'Labios vs audio',             val: lipsyncRisk, desc:'Baja correlación entre actividad oral y energía de voz.'},
      {key:'blink',  name:'Parpadeo anómalo',            val: blinkRisk, desc:'Frecuencia de parpadeo fuera de lo fisiológico.'},
      {key:'name',   name:'Pistas del nombre',           val: nameRisk, desc:'Keywords o resoluciones crudas en el nombre del archivo.'}
    ];

    let w;
    if (onnxProb==null) {
      // Perfil agresivo por defecto: castiga “perfección digital”
      w = (prof==='aggressive')
        ? { onnx:0, flicker:.08, dct:.12, block:.12, sharp:.14, sat:.14, gcontrast:.10, sensor:.14, skin:.10, lips:.04, blink:.02, name:.00 }
        : { onnx:0, flicker:.10, dct:.12, block:.12, sharp:.12, sat:.10, gcontrast:.08, sensor:.12, skin:.10, lips:.08, blink:.06, name:.00 };
    } else {
      w = (prof==='aggressive')
        ? { onnx:.50, flicker:.05, dct:.08, block:.06, sharp:.09, sat:.09, gcontrast:.05, sensor:.06, skin:.05, lips:.03, blink:.02, name:.00 }
        : { onnx:.55, flicker:.05, dct:.07, block:.05, sharp:.07, sat:.07, gcontrast:.04, sensor:.05, skin:.04, lips:.03, blink:.02, name:.00 };
    }

    const score01 = clamp(metrics.reduce((acc,m)=> acc + m.val*(w[m.key]||0), 0), 0, 1);
    const scorePct = Math.round(score01*100);
    const thr = parseInt(thres.value,10);
    const label = scorePct < (thr-10) ? 'Baja sospecha' : scorePct < (thr+10) ? 'Incierto' : 'Alta sospecha';

    const detail = metrics.map(m=>({ key:m.key, name:m.name, desc:m.desc, risk01:+m.val.toFixed(3)}));

    return {
      summary: {
        scorePct, label, frames: frames.length, fps, duration:+duration.toFixed(1),
        threshold: thr, onnx: onnxProb!=null, faceLandmarks: faceReady,
        bitrate_bps: approxBitratebps(currentFile, duration) ? Math.round(approxBitratebps(currentFile, duration)) : null
      },
      metrics: detail,
      blink: blink || null,
      lipsync: lipsync || null,
      name: { file: currentFile?.name || null, risk01: nameRisk },
      tech: {
        means: { meanY:+mean(meanY).toFixed(2), block:+mean(block).toFixed(3), sharp:+mean(sharp).toFixed(2) },
        std:   { meanY:+stdDev(meanY).toFixed(3) }
      }
    };
  }

  async function ensureMetadata(video){
    return new Promise((res, rej)=>{
      if(isFinite(video.duration) && video.duration>0) return res();
      const onLoaded=()=>{ cleanup(); res(); }; const onErr=()=>{ cleanup(); rej(new Error('No se pudo leer metadatos')); };
      function cleanup(){ video.removeEventListener('loadedmetadata', onLoaded); video.removeEventListener('error', onErr); }
      video.addEventListener('loadedmetadata', onLoaded); video.addEventListener('error', onErr); if(video.readyState>=1) onLoaded();
    });
  }

  async function captureFrames(video, fps, maxFrames, capDuration, onProgress){
    const frames=[]; const times=[]; work.width=320; work.height=Math.round(320/(video.videoWidth/video.videoHeight || (16/9)));
    const start=0, end=Math.min(capDuration, video.duration||capDuration); const step=1/fps; const total=Math.min(Math.ceil((end-start)*fps), maxFrames);
    for(let i=0;i<total;i++){
      const t = start + i*step; if(t>end) break; const target = Math.min(t, end-0.001);
      video.currentTime = target; await once(video,'seeked'); wctx.drawImage(video,0,0,work.width,work.height);
      frames.push(wctx.getImageData(0,0,work.width,work.height)); times.push(target);
      if(onProgress) onProgress(Math.round((frames.length/total)*100));
    }
    return {frames, times};
  }

  // =============== Frame-level features ===============
  function frameStats(img){
    const { data, width:w, height:h } = img; const n=w*h; let sumY=0; let lapEnergy=0; let blockiness=0; const k=[-1,-1,-1,-1,8,-1,-1,-1,-1];
    const gray = new Float32Array(n);
    for(let i=0,j=0;i<data.length;i+=4,j++){ const r=data[i],g=data[i+1],b=data[i+2]; const y=0.299*r+0.587*g+0.114*b; sumY+=y; gray[j]=y; }
    const W=w,H=h, idx=(x,y)=>y*W+x;
    for(let y=1;y<H-1;y++){
      for(let x=1;x<W-1;x++){
        const g00=gray[idx(x-1,y-1)], g01=gray[idx(x,y-1)], g02=gray[idx(x+1,y-1)];
        const g10=gray[idx(x-1,y)],   g11=gray[idx(x,y)],   g12=gray[idx(x+1,y)];
        const g20=gray[idx(x-1,y+1)], g21=gray[idx(x,y+1)], g22=gray[idx(x+1,y+1)];
        const conv = k[0]*g00+k[1]*g01+k[2]*g02+k[3]*g10+k[4]*g11+k[5]*g12+k[6]*g20+k[7]*g21+k[8]*g22; lapEnergy += Math.abs(conv);
        if(x%8===0) blockiness += Math.abs(g11-g12); if(y%8===0) blockiness += Math.abs(g11-g21);
      }
    }
    const area=(W-2)*(H-2); lapEnergy/=area; blockiness/=area; const meanY=sumY/n; return { meanY, lapEnergy, blockiness };
  }

  function detectFace(img){
    if(!faceLandmarker) return null;
    // Draw image data to an offscreen canvas to use with MediaPipe
    const tmp = document.createElement('canvas'); tmp.width = img.width; tmp.height = img.height; const tctx = tmp.getContext('2d'); tctx.putImageData(img,0,0);
    const res = faceLandmarker.detect(tmp);
    if(!res || !res.faceLandmarks || !res.faceLandmarks[0]) return null;
    const lm = res.faceLandmarks[0];
    // BBox
    let minX=1e9,minY=1e9,maxX=-1e9,maxY=-1e9; for(const p of lm){ const x=p.x*img.width, y=p.y*img.height; if(x<minX)minX=x; if(y<minY)minY=y; if(x>maxX)maxX=x; if(y>maxY)maxY=y; }
    const cx=(minX+maxX)/2, cy=(minY+maxY)/2; let w=maxX-minX, h=maxY-minY; const d=Math.max(w,h)*CFG.faceCropScale; const x0=Math.max(0, Math.round(cx-d/2)), y0=Math.max(0, Math.round(cy-d/2)); const x1=Math.min(img.width, Math.round(cx+d/2)), y1=Math.min(img.height, Math.round(cy+d/2));
    // Face patch 224x224
    const faceW = x1-x0, faceH=y1-y0; const faceImg = new ImageData(faceW, faceH);
    for(let y=0;y<faceH;y++){
      for(let x=0;x<faceW;x++){
        const srcIdx = ((y0+y)*img.width + (x0+x)) * 4; const dstIdx = (y*faceW + x) * 4;
        faceImg.data[dstIdx]=img.data[srcIdx]; faceImg.data[dstIdx+1]=img.data[srcIdx+1]; faceImg.data[dstIdx+2]=img.data[srcIdx+2]; faceImg.data[dstIdx+3]=255;
      }
    }
    fctx.clearRect(0,0,faceC.width,faceC.height);
    const tmp2 = document.createElement('canvas'); tmp2.width=faceW; tmp2.height=faceH; const c2=tmp2.getContext('2d'); c2.putImageData(faceImg,0,0); fctx.drawImage(tmp2,0,0,faceC.width,faceC.height);

    // EAR/MAR
    const idxsR = [33,160,158,133,153,144]; const idxsL = [362,385,387,263,373,380];
    const earR = eyeAspectRatio(lm, idxsR, img); const earL = eyeAspectRatio(lm, idxsL, img); const ear = (earR+earL)/2;
    const mar = mouthAspectRatio(lm, {L:78, R:308, T:13, B:14}, img);

    return { patch: fctx.getImageData(0,0,faceC.width,faceC.height), ear, mar };
  }

  function eyeAspectRatio(lm, idxs, img){
    const pts = idxs.map(i=>({x: lm[i].x*img.width, y: lm[i].y*img.height}));
    const A = dist(pts[1], pts[5]); const B = dist(pts[2], pts[4]); const C = dist(pts[0], pts[3]);
    return (A+B) / (2*C + 1e-6);
  }
  function mouthAspectRatio(lm, m, img){
    const L = {x: lm[m.L].x*img.width, y: lm[m.L].y*img.height};
    const R = {x: lm[m.R].x*img.width, y: lm[m.R].y*img.height};
    const T = {x: lm[m.T].x*img.width, y: lm[m.T].y*img.height};
    const B = {x: lm[m.B].x*img.width, y: lm[m.B].y*img.height};
    const horiz = dist(L,R); const vert = dist(T,B);
    return vert/(horiz+1e-6);
  }
  const dist = (a,b)=> Math.hypot(a.x-b.x, a.y-b.y);

  async function runOnnx(patch){
    if(!session) return null;
    // Preprocess 224x224 RGBA -> NCHW float32 0..1
    const {data,width,height} = patch; const N=1,C=3,H=224,W=224; const input = new Float32Array(N*C*H*W);
    let p=0; for(let y=0;y<H;y++){
      for(let x=0;x<W;x++){
        const idx = (y*width + x) * 4; const r=data[idx]/255, g=data[idx+1]/255, b=data[idx+2]/255;
        input[p++] = r;
      }
    }
    for(let y=0;y<H;y++) for(let x=0;x<W;x++){ const idx=(y*width + x)*4; input[p++] = patch.data[idx+1]/255; }
    for(let y=0;y<H;y++) for(let x=0;x<W;x++){ const idx=(y*width + x)*4; input[p++] = patch.data[idx+2]/255; }

    const feeds = {}; feeds[session.inputNames[0]] = new ort.Tensor('float32', input, [1,3,224,224]);
    try{
      const out = await session.run(feeds); const key = session.outputNames[0]; let val = out[key].data[0];
      if(!isFinite(val) || Math.abs(val)>1){ val = 1/(1+Math.exp(-val)); } // logits -> prob
      return clamp(val,0,1);
    }catch{ return null; }
  }

  function dctHighFreq(patch){
    // Grayscale 64x64 y DCT2, proporción de energía en altas frecuencias (0..1)
    const S=64; const c=document.createElement('canvas'); c.width=S; c.height=S; const ctx=c.getContext('2d'); const tmp=document.createElement('canvas'); tmp.width=patch.width; tmp.height=patch.height; tmp.getContext('2d').putImageData(patch,0,0); ctx.drawImage(tmp,0,0,S,S); const img=ctx.getImageData(0,0,S,S).data;
    const g=new Float32Array(S*S); for(let i=0,j=0;i<img.length;i+=4,j++){ g[j]=0.299*img[i]+0.587*img[i+1]+0.114*img[i+2]; }
    const C = new Float32Array(S*S);
    const PI=Math.PI; const alpha = (u)=> u===0? Math.SQRT1_2 : 1;
    for(let u=0;u<S;u++){
      for(let v=0;v<S;v++){
        let sum=0; for(let x=0;x<S;x++) for(let y=0;y<S;y++){ sum += g[y*S+x]*Math.cos(((2*x+1)*u*PI)/(2*S))*Math.cos(((2*y+1)*v*PI)/(2*S)); }
        C[v*S+u] = 0.25*alpha(u)*alpha(v)*sum;
      }
    }
    let total=0, high=0; const cutoff=16; for(let v=0; v<S; v++) for(let u=0; u<S; u++){ const e=C[v*S+u]*C[v*S+u]; total+=e; if(u+v>cutoff) high+=e; }
    return clamp(high/(total+1e-6), 0, 1);
  }

  function skinChromVar(patch){
    // Varianza de crominancia U/V en la cara (proxy simple)
    const {data,width,height}=patch; const n=width*height; let sumU=0,sumV=0; const U=new Float32Array(n), V=new Float32Array(n);
    for(let i=0,j=0;i<data.length;i+=4,j++){
      const r=data[i]/255, g=data[i+1]/255, b=data[i+2]/255;
      const y=0.299*r+0.587*g+0.114*b; const u=0.492*(b - y); const v=0.877*(r - y); U[j]=u; V[j]=v; sumU+=u; sumV+=v;
    }
    const mU=sumU/n, mV=sumV/n; let sU=0,sV=0; for(let i=0;i<n;i++){ sU+=(U[i]-mU)**2; sV+=(V[i]-mV)**2; }
    return clamp((Math.sqrt(sU/n)+Math.sqrt(sV/n)) / 0.35, 0, 1);
  }

  // ===== Saturación y contraste global =====
  function saturationStats(img) {
    const {data} = img;
    let sumS = 0; const Svals = [];
    for (let i=0; i<data.length; i+=4) {
      const r=data[i]/255, g=data[i+1]/255, b=data[i+2]/255;
      const max = Math.max(r,g,b), min = Math.min(r,g,b);
      const v = max; const s = v === 0 ? 0 : (max - min) / v; // HSV
      sumS += s; Svals.push(s);
    }
    Svals.sort((a,b)=>a-b);
    const p95 = Svals[Math.floor(0.95*(Svals.length-1))] || 0;
    return { meanS: sumS / (data.length/4), p95S: p95 };
  }

  function contrastGlobal(img) {
    const {data} = img;
    const Y = [];
    for (let i=0; i<data.length; i+=4) {
      Y.push(0.299*data[i]+0.587*data[i+1]+0.114*data[i+2]);
    }
    const m = Y.reduce((a,b)=>a+b,0)/Y.length;
    let v=0; for (const y of Y){ const d=y-m; v+=d*d; }
    const sd = Math.sqrt(v/Math.max(1,Y.length));
    Y.sort((a,b)=>a-b);
    const p05 = Y[Math.floor(0.05*(Y.length-1))] || 0;
    const p95 = Y[Math.floor(0.95*(Y.length-1))] || 0;
    return { sd, range: p95 - p05 };
  }

  // =============== Blink & lipsync ===============
  function blinkStats(earSeries, fps){
    if(!earSeries || earSeries.length<3) return null; const thr=0.21; let blinks=0, lastLow=false; for(const v of earSeries){ const low=v<thr; if(low && !lastLow) blinks++; lastLow=low; }
    const durationMin = earSeries.length / fps / 60; const rate = blinks / Math.max(0.01, durationMin);
    let risk = 0; if(rate<3) risk = 0.9; else if(rate<6) risk=0.6; else if(rate>35) risk=0.6; else risk=0.2; return { blinks, ratePerMin: +rate.toFixed(1), risk01: clamp(risk,0,1) };
  }

  async function lipsyncCorrelation(times, marSeries, audioBuffer){
    if(!audioBuffer || !marSeries || marSeries.length<6) return null;
    const sr = audioBuffer.sampleRate; const ch = audioBuffer.getChannelData(0); const win = Math.floor(0.04*sr);
    const rms=[]; for(const t of times){ const idx=Math.floor(t*sr); let s=0,n=0; for(let i=idx-win;i<=idx+win;i++){ if(i>=0 && i<ch.length){ const v=ch[i]; s+=v*v; n++; } } rms.push(Math.sqrt(s/Math.max(1,n))); }
    const a = zscore(marSeries); const b = zscore(rms);
    const corr = pearson(a,b);
    const speechEnergy = mean(rms);
    const risk = speechEnergy>0.02 ? clamp(0.7 - corr*0.7, 0, 1) : 0.3;
    return { corr:+corr.toFixed(2), energy:+speechEnergy.toFixed(3), risk01:risk };
  }

  // =============== Helpers ===============
  const mean = arr => arr.reduce((a,b)=>a+b,0)/arr.length;
  const diff = arr => arr.slice(1).map((v,i)=> v - arr[i]);
  const stdDev = arr => { const m=mean(arr); let s=0; for(const v of arr){ s+=(v-m)*(v-m); } return Math.sqrt(s/arr.length); }
  const clamp = (x,a,b)=> Math.max(a, Math.min(b, x));
  const scale = (v, lo, hi)=> clamp((v - lo) / (hi - lo), 0, 1);
  const uShape = (v, lo, hi)=>{ if(hi<=lo) return 0; const mid=(lo+hi)/2; const span=(hi-lo)/2; const d=Math.abs(v-mid)/span; return clamp(d,0,1); };
  const zscore = arr => { const m=mean(arr), s=stdDev(arr)||1; return arr.map(v=>(v-m)/s); };
  const pearson = (a,b)=>{ const ma=mean(a), mb=mean(b); let num=0,da=0,db=0; for(let i=0;i<a.length;i++){ const x=a[i]-ma, y=b[i]-mb; num+=x*y; da+=x*x; db+=y*y; } return num/Math.sqrt((da||1)*(db||1)); };

  // Perfección digital
  const lowRisk = (v, lo, hi) => clamp((hi - v) / Math.max(1e-6, hi - lo), 0, 1);

  function frameNoiseRMS(img) {
    const {data,width:w,height:h}=img;
    const toGray = (i)=> 0.299*data[i]+0.587*data[i+1]+0.114*data[i+2];
    const g = new Float32Array(w*h);
    for(let i=0,j=0;i<data.length;i+=4,j++) g[j]=toGray(i);
    const idx = (x,y)=> y*w+x;
    const out = new Float32Array(w*h);
    for(let y=1;y<h-1;y++){
      for(let x=1;x<w-1;x++){
        const b = (
          g[idx(x-1,y-1)] + g[idx(x,y-1)] + g[idx(x+1,y-1)] +
          g[idx(x-1,y  )] + g[idx(x,y  )] + g[idx(x+1,y  )] +
          g[idx(x-1,y+1)] + g[idx(x,y+1)] + g[idx(x+1,y+1)]
        )/9;
        out[idx(x,y)] = g[idx(x,y)] - b; // residuo HF
      }
    }
    let sum=0,n=0;
    for(let y=1;y<h-1;y++) for(let x=1;x<w-1;x++){ const v=out[idx(x,y)]; sum+=v*v; n++; }
    return Math.sqrt(sum/Math.max(1,n));
  }

  function localContrast(facePatch) {
    const {data,width:w,height:h}=facePatch;
    const toGray = (i)=> 0.299*data[i]+0.587*data[i+1]+0.114*data[i+2];
    const n = w*h;
    let s=0; for(let i=0;i<data.length;i+=4) s+=toGray(i);
    const m = s/n;
    let v=0; for(let i=0;i<data.length;i+=4){ const d=toGray(i)-m; v+=d*d; }
    return Math.sqrt(v/Math.max(1,n));
  }

  function approxBitratebps(file, durationSec){
    if(!file || !durationSec || durationSec<=0) return null;
    return (file.size * 8) / durationSec; // bits por segundo
  }

  // =============== Render + Tooltips ===============
  function renderReport(rep){
    setGauge(rep.summary.scorePct, rep.summary.label);
    legendEl.innerHTML='';
    rep.metrics.forEach(m=> legendEl.appendChild(metricRow(m.name, Math.round(m.risk01*100), m.desc)));
  }

  function metricRow(name, pct, desc){
    const row=document.createElement('div'); row.className='metric-row';
    const n=document.createElement('div'); n.className='name'; n.textContent=name; n.tabIndex=0;
    n.addEventListener('mouseenter', (e)=> showTip(desc, e));
    n.addEventListener('mousemove', (e)=> moveTip(e));
    n.addEventListener('mouseleave', hideTip);
    n.addEventListener('focus', (e)=> showTip(desc, e)); // accesible
    n.addEventListener('blur', hideTip);

    const bar=document.createElement('div'); bar.className='bar';
    const fill=document.createElement('span'); fill.style.width=pct+'%'; bar.appendChild(fill);
    const v=document.createElement('div'); v.className='val'; v.textContent=pct+'%';
    row.append(n,bar,v); return row;
  }

  function showTip(text, ev){
    tooltip.textContent = text || '—';
    tooltip.classList.add('show');
    moveTip(ev);
  }
  function moveTip(ev){
    const pad=12; const {clientX:x, clientY:y} = ev;
    const w = tooltip.offsetWidth || 240; const h = tooltip.offsetHeight || 80;
    let tx = x + 14, ty = y + 14;
    if(tx + w + pad > window.innerWidth)  tx = x - w - 14;
    if(ty + h + pad > window.innerHeight) ty = y - h - 14;
    tooltip.style.left = tx + 'px'; tooltip.style.top = ty + 'px';
  }
  function hideTip(){ tooltip.classList.remove('show'); }

  function setGauge(pct,label){ pct=Math.round(pct); drawGauge(gaugeCanvas,pct); pctEl.textContent=isFinite(pct)? pct+'%':'—%'; labelEl.textContent=label||'—'; }
  function drawGauge(canvas,pct){ const ctx=canvas.getContext('2d'); const w=canvas.width,h=canvas.height,r=w/2-8,cx=w/2,cy=h/2; ctx.clearRect(0,0,w,h); ctx.lineWidth=12; ctx.strokeStyle='rgba(255,255,255,.12)'; ctx.beginPath(); ctx.arc(cx,cy,r, Math.PI*0.75, Math.PI*2.25); ctx.stroke(); const t=pct/100; const start=Math.PI*0.75; const end=start + t*(Math.PI*1.5); const grad=ctx.createLinearGradient(0,0,w,0); grad.addColorStop(0,'#7aa2ff'); grad.addColorStop(1,'#8af0d6'); ctx.strokeStyle=grad; ctx.lineWidth=12; ctx.lineCap='round'; ctx.beginPath(); ctx.arc(cx,cy,r,start,end); ctx.stroke(); }

  // =============== Filename risk cues ===============
  function filenameRisk(name){
    if(!name) return 0; const low=name.toLowerCase(); const hints=['deepfake','faceswap','fsgan','roop','sdxl','synth','ai','gen','xseg','dfaker','vid2vid','gfpgan'];
    let score=0; for(const h of hints){ if(low.includes(h)) score+=0.2; } if(/[0-9]{3,4}x[0-9]{3,4}/.test(low)) score+=0.05; return clamp(score,0,1);
  }
  </script>
</body>
</html>
